{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Regressor Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from scipy.stats import pearsonr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options to show all rows and columns\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = \"./gaitrec_data\"\n",
    "# Train set\n",
    "UNBALANCED_TRAIN_SET_METADATA_PATH = os.path.join(DATA_ROOT, \"unbalanced_train_set_metadata.csv\")\n",
    "POSTPROCESSED_TRAIN_FOLDER = os.path.join(DATA_ROOT, 'postprocessed_train')\n",
    "GROUPS_SESSIONS_DATA_TRAIN = os.path.join(DATA_ROOT, 'groups_sessions_data_train')\n",
    "GRF_F_AP_PRO_DATA_TRAIN = os.path.join(DATA_ROOT, 'GRF_F_AP_PRO_data_train')\n",
    "# Test set\n",
    "TEST_SET_METADATA_PATH = os.path.join(DATA_ROOT, \"test_set_metadata.csv\")\n",
    "TEST_FOLDER = os.path.join(DATA_ROOT, \"test_set\")\n",
    "GROUPS_SESSIONS_DATA_TEST = os.path.join(DATA_ROOT, 'groups_sessions_data_test')\n",
    "GRF_F_AP_PRO_DATA_TEST = os.path.join(DATA_ROOT, 'GRF_F_AP_PRO_data_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separar las features del target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Separar las features (valores de la primera sesión) y el target (valores de la última sesión).\n",
    "- Los valores de la primera sesión corresponden a las filas impares y los valores de la última sesión corresponden a las filas pares. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df_train_test(df_train: pd.DataFrame, df_test: pd.DataFrame):\n",
    "    # Select only the columns of interest\n",
    "    columns_of_interest = df_train.columns[3:]  # Exclude SUBJECT_ID, SESSION_ID, TRIAL_ID\n",
    "    # Create X_train, y_train, X_test, y_test:\n",
    "        # Extract the odd rows into X\n",
    "        # Extract the even rows into y\n",
    "    X_train = df_train.iloc[::2][columns_of_interest].values\n",
    "    y_train = df_train.iloc[1::2][columns_of_interest].values\n",
    "    X_test = df_test.iloc[::2][columns_of_interest].values\n",
    "    y_test = df_test.iloc[1::2][columns_of_interest].values\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load preprocessed data\n",
    "- ANKLE data - 2 sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train df\n",
    "combined_legs_2sessions_A_train = pd.read_csv(os.path.join(GRF_F_AP_PRO_DATA_TRAIN, \n",
    "                              'groups_2sessions_data_train/A_data/combined.csv'))\n",
    "# test df\n",
    "combined_legs_2sessions_A_test = pd.read_csv(os.path.join(GRF_F_AP_PRO_DATA_TEST, \n",
    "                              'groups_2sessions_data_test/A_data/combined.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train - test split \n",
    "X_train_A2, y_train_A2, X_test_A2, y_test_A2 = split_df_train_test(df_train = combined_legs_2sessions_A_train, \n",
    "                                                                   df_test = combined_legs_2sessions_A_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_xgboost(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Train and evaluate an XGBoost Regressor with hyperparameter tuning.\n",
    "\n",
    "    Parameters:\n",
    "        X_train (np.ndarray): Training data with shape (num_samples, num_features).\n",
    "        y_train (np.ndarray): Training target data with shape (num_samples, num_targets).\n",
    "\n",
    "    Returns:\n",
    "        xgb.XGBRegressor: Fitted XGBoost model.\n",
    "        float: Root mean square error (RMSE) score.\n",
    "        float: R-squared score.\n",
    "        float: Correlation coefficient (Pearson's r).\n",
    "    \"\"\"\n",
    "    # Initialize an XGBoost model\n",
    "    xgboost = xgb.XGBRegressor(random_state=42)\n",
    "\n",
    "    # Define a range of hyperparameters for tuning\n",
    "    param_dist = {\n",
    "        'n_estimators': [10, 100, 300, 500, 800, 1000, 2000, 3000, 4000, 5000], # int ranging from 10 to 5000\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3, 1.0], # real ranging from 0.01 to 1.0\n",
    "        'min_child_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], # int between 1 and 10\n",
    "        'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30, 35, 40, 45, 50], # int between 1 and 50 \n",
    "        'max_delta_step': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20], # int between 0 and 20\n",
    "        'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], # real from 0.1 to 1.0\n",
    "        'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], # real from 0.1 to 1.0\n",
    "        'colsample_bylevel': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], # real from 0.1 to 1.0\n",
    "        'reg_lambda': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1.0, 10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0, 80.0, 90.0, 100.0], # real between 1e-9 and 100.0\n",
    "        'reg_alpha': [1e-9, 0.1, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, 4.0, 5.0, 10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0, 80.0, 90.0, 100.0], # real between 1e-9 and 100.0\n",
    "        'gamma': [1e-9, 0.1, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, 4.0, 5.0, 10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0, 80.0, 90.0, 100.0], # real between 1e-9 and 100.0\n",
    "        'scale_pos_weight': [1e-6, 1.0, 2.0, 3.0, 4.0, 5.0, 10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0, 80.0, 90.0, 100.0, 200.0, 300.0, 400.0, 500.0] # real between 1e-6 and 500.0\n",
    "    }\n",
    "\n",
    "    # Create RandomizedSearchCV object with 10-fold cross-validation\n",
    "    random_search = RandomizedSearchCV(estimator=xgboost,\n",
    "                                       param_distributions=param_dist,\n",
    "                                       cv=5,\n",
    "                                       n_iter=10,\n",
    "                                       scoring=make_scorer(mean_squared_error, squared=False, greater_is_better=False),\n",
    "                                       n_jobs=-1)\n",
    "    \n",
    "    # Fit the RandomizedSearchCV object on the training data\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_params = random_search.best_params_\n",
    "    print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "    # Train the XGBoost model with the best hyperparameters\n",
    "    best_xgboost = xgb.XGBRegressor(**best_params, random_state=42)\n",
    "    best_xgboost.fit(X_train, y_train)\n",
    "\n",
    "    # Perform cross-validation and get predicted values\n",
    "    predicted_y = cross_val_predict(best_xgboost, X_train, y_train, cv=10)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_train, predicted_y))\n",
    "\n",
    "    # Calculate R2 score\n",
    "    r2 = r2_score(y_train, predicted_y)\n",
    "\n",
    "    # Calculate correlation coefficient\n",
    "    corr_coeff, _ = pearsonr(y_train.flatten(), predicted_y.flatten())\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Results on Training Set:\")\n",
    "    print(f\" RMSE: {rmse:.3f}\")\n",
    "    print(f\" R2 Score: {r2:.3f}\")\n",
    "    print(f\" Correlation coefficient: {corr_coeff:.3f}\")\n",
    "\n",
    "    return best_xgboost, rmse, r2, corr_coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernatsort/Library/CloudStorage/OneDrive-LaSalle/1. MASTER_DS/TFM/Therapy-Progress-Gait-Prediction/tfm_env/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'subsample': 0.8, 'scale_pos_weight': 80.0, 'reg_lambda': 1e-06, 'reg_alpha': 0.8, 'n_estimators': 4000, 'min_child_weight': 8, 'max_depth': 30, 'max_delta_step': 2, 'learning_rate': 0.05, 'gamma': 1e-09, 'colsample_bytree': 0.2, 'colsample_bylevel': 0.9}\n",
      "Results on Training Set:\n",
      " RMSE: 0.018\n",
      " R2 Score: 0.336\n",
      " Correlation coefficient: 0.982\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the XGBoost Regressor (model 14)\n",
    "xgb_model, rmse_xgb, r2_xgb, corr_xgb = train_and_evaluate_xgboost(X_train = X_train_A2, \n",
    "                                                                   y_train = y_train_A2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Hyperparameters: {'subsample': 0.5, 'scale_pos_weight': 90.0, 'reg_lambda': 80.0, 'reg_alpha': 0.1, 'n_estimators': 1000, 'min_child_weight': 5, 'max_depth': 1, 'max_delta_step': 3, 'learning_rate': 0.01, 'gamma': 1.0, 'colsample_bytree': 0.1, 'colsample_bylevel': 0.1}\n",
    "Results on Training Set:\n",
    " RMSE: 0.026\n",
    " R2 Score: -0.078\n",
    " Correlation coefficient: 0.960\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
